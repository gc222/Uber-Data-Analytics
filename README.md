# Uber Data Analytics | Data Engineering GCP Project

### Introduction
The project showcases an end-to-end data engineering and analytics pipeline built using Uber trip data. The goal is to ingest raw trip
records, perform transformations and data modelling, and surface business and operational insights via visualisations. The project leverages a
modern data engineering stack including GCP services and tools, demonstrating core data engineering concepts including ingestion, transformation, modelling, 
and analytics delivery.

System Architecture


1. Data Ingestion
The trip data is stored in Google Cloud Storage.

2. Transformation


---
### Technology Stack
Programming Language
- Python

1. Google Cloud Storage - A scalable, efficient, and secure cloud storage 
2. Compute Engine - Provides virtual machine instances to host and run the data pipeline
3. Google Big Query - Data warehouse for storing and querying the dataset
4. Google Looker Studio
5. Mage Data Pipeline Tool



Dataset
The dataset used in this project is sourced from TLC Trip Record Data Yellow and Green taxi records which includes key fields 
capturing vendor, pick-up and drop-off date/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, 
and driver-reported passenger counts.

More information about the dataset can be found here:
1. Website link: https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page
2. Data Dictionary: https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf
